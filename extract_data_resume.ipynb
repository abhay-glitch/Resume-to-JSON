{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a94dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Extracting text from sample_resume.pdf...\n",
      "\n",
      "📄 Resume Text Extracted:\n",
      "\n",
      "John Doe\n",
      "Email: john.doe@example.com\n",
      "Phone: +1 234 567 8901\n",
      "Address: 123 Main Street, New York, NY\n",
      "Summary\n",
      "A highly motivated software engineer with 3+ years of experience in Python and AI.\n",
      "Skills\n",
      "- Python, Java, SQL\n",
      "- Machine Learning, Deep Learning, NLP\n",
      "- Git, Docker, Linux\n",
      "Experience\n",
      "Software Engineer - ABC Corp (2021 - Present)\n",
      "- Developed AI models for predictive analytics.\n",
      "- Improved system performance by 20%.\n",
      "Intern - XYZ Ltd (2020 - 2021)\n",
      "- Assisted in developing web applications.\n",
      "- Wrote automated scripts for testing.\n",
      "Education\n",
      "B.Tech in Computer Science - ABC University (2016 - 2020)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import docx\n",
    "\n",
    "def extract_from_pdf(file_path):\n",
    "    \"\"\"Extract text from PDF using pdfplumber\"\"\"\n",
    "    text = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text.append(page_text)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def extract_from_docx(file_path):\n",
    "    \"\"\"Extract text from DOCX using python-docx\"\"\"\n",
    "    doc = docx.Document(file_path)\n",
    "    text = [para.text for para in doc.paragraphs if para.text.strip()]\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def extract_from_txt(file_path):\n",
    "    \"\"\"Extract text from TXT file\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def extract_resume_text(file_path):\n",
    "    \"\"\"Detect file type and extract text\"\"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        return extract_from_pdf(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        return extract_from_docx(file_path)\n",
    "    elif ext == \".txt\":\n",
    "        return extract_from_txt(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use PDF, DOCX, or TXT.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_file = \"sample_resume.pdf\"  \n",
    "\n",
    "    print(f\"📂 Extracting text from {resume_file}...\\n\")\n",
    "    text = extract_resume_text(resume_file)\n",
    "\n",
    "    print(\"📄 Resume Text Extracted:\\n\")\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7fe6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- My Data Note ---\n",
      "The cat sat on the mat. It was a fluffy cat.\n",
      "\n",
      "--- My Prompt Note ---\n",
      "Describe the cat based on the provided information.\n",
      "\n",
      "--- Gemma's Answer Note ---\n",
      "This little cat is very comfortable!  \n",
      "\n",
      "**We know:**\n",
      "\n",
      "* **Location:** It's sitting on a mat. \n",
      "* **Appearance:**  It's \"fluffy,\" which means it has soft, puffy fur.\n",
      "\n",
      "You probably wouldn't be able to tell its exact color or age just from this description alone, but the fluffy coat suggests a sweet and cuddly cat! 😻 \n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Long Text ---\n",
      "The quick brown fox jumps over the lazy dog. This is a classic pangram, a sentence containing every letter of the alphabet at least once. It is often used for typing practice.\n",
      "\n",
      "--- Summarize Instruction ---\n",
      "Summarize the following text in one short sentence:\n",
      "\n",
      "--- Gemma's Summary ---\n",
      "The sentence \"The quick brown fox jumps over the lazy dog\" is a classic pangram used for teaching typing skills. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama \n",
    "\n",
    "def ask_gemma(my_data_note: str, my_prompt_note: str) -> str:\n",
    "    \"\"\"\n",
    "    This function is like giving your two sticky notes to Gemma.\n",
    "    It takes what's on your 'data' note and your 'prompt' note,\n",
    "    and asks Gemma to generate a response.\n",
    "    \"\"\"\n",
    "\n",
    "    message_for_gemma = f\"{my_prompt_note}\\n\\nHere is the information: {my_data_note}\"\n",
    "\n",
    "    try:\n",
    "        # Gemma reads the message and thinks!\n",
    "        # 'gemma2:2b' is the specific smart helper we're using.\n",
    "        gemma_response_object = ollama.generate(\n",
    "            model='gemma2:2b',\n",
    "            prompt=message_for_gemma\n",
    "        )\n",
    "\n",
    "        # Gemma finishes thinking and gives us its answer.\n",
    "        # The actual text answer is inside 'gemma_response_object'\n",
    "        # in something called 'response'.\n",
    "        gemma_final_answer = gemma_response_object['response']\n",
    "\n",
    "        return gemma_final_answer # We give you back Gemma's answer!\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Oops! Something went wrong: {e}\")\n",
    "        print(\"Make sure Ollama is running and you have 'gemma2:2b' installed.\")\n",
    "        return \"Sorry, I couldn't get an answer.\"\n",
    "\n",
    "# --- Let's try it with some real sticky notes! ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 📝 First sticky note: My Data\n",
    "    my_data_to_give_gemma = \"The cat sat on the mat. It was a fluffy cat.\"\n",
    "\n",
    "    # ❓ Second sticky note: My Prompt (Instructions for Gemma)\n",
    "    my_prompt_for_gemma = \"Describe the cat based on the provided information.\"\n",
    "\n",
    "    # ✨ Third sticky note: This is where Gemma's answer will go!\n",
    "    gemma_result_note = ask_gemma(my_data_to_give_gemma, my_prompt_for_gemma)\n",
    "\n",
    "    # 🎉 Now, let's see what Gemma wrote on the third sticky note!\n",
    "    print(\"--- My Data Note ---\")\n",
    "    print(my_data_to_give_gemma)\n",
    "    print(\"\\n--- My Prompt Note ---\")\n",
    "    print(my_prompt_for_gemma)\n",
    "    print(\"\\n--- Gemma's Answer Note ---\")\n",
    "    print(gemma_result_note)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # --- Another example: Asking Gemma to summarize ---\n",
    "    long_text = \"The quick brown fox jumps over the lazy dog. This is a classic pangram, a sentence containing every letter of the alphabet at least once. It is often used for typing practice.\"\n",
    "    summarize_instruction = \"Summarize the following text in one short sentence:\"\n",
    "\n",
    "    summary_from_gemma = ask_gemma(long_text, summarize_instruction)\n",
    "\n",
    "    print(\"--- Long Text ---\")\n",
    "    print(long_text)\n",
    "    print(\"\\n--- Summarize Instruction ---\")\n",
    "    print(summarize_instruction)\n",
    "    print(\"\\n--- Gemma's Summary ---\")\n",
    "    print(summary_from_gemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4311b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting httpx>=0.27 (from ollama)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\abc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ollama) (2.11.7)\n",
      "Collecting anyio (from httpx>=0.27->ollama)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\abc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->ollama) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx>=0.27->ollama)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\abc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27->ollama)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\abc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27->ollama)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading ollama-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, h11, httpcore, anyio, httpx, ollama\n",
      "\n",
      "   ------ --------------------------------- 1/6 [h11]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   ---------------------------------------- 6/6 [ollama]\n",
      "\n",
      "Successfully installed anyio-4.10.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ollama-0.5.3 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea079e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbcde7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59033c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fca74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb7583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d13597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce745e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
